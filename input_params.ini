[PARAMETERS]

# type of data in data stream. 0 for load pattern, 1 for load time series
data_type = 1

 # number of data points input to algorithm at a time
batch_size = 1

 # number of data points to buffer before initialising clusters. Only used in basic online periodic kmeans++.
init_batch_size = 100

# Number of clusters to start with in optimal K algorithm. Number of clusters used throughout in basic kmeans++ algoirthm.
init_num_clusters = 2

# tolerance for error when converging on clustering solution
tol = 1e-4

# max number of iterations when converging on clustering solution
max_iter = 300

# degree to which a new data point 'pulls' other centre of masses towards it. Only used in gravitational optimal K algorithm.
# for no gravitational effect set to 0
gravitational_const = 1

# number of data samples after which a cluster should be killed if it has not received a most likely data point in
# that time
time_decay_const = 96

# type of clustering algorithm to use. 0 for Online Periodic KMeans++, 1 for online Optimal-K KMeans++ algorithm,
# 2 for offline optimal kmeans++ algorithm
# algorithm = 0
algorithm = 1
# algorithm = 2

# maximum number of samples of data stream to run in test. Equal to positive integer or all
num_samples_to_run = all

# Name to give this test-run, this will be the name of the folder in which all results for this run are stored
# test_name = Online Periodic Re-Init KMeans++
test_name = Online Optimal-K KMeans++ with High-Alpha
# test_name = Offline Optimal-K KMeans++

# steps over data stream at which to plot results
plotting_data_step = 1000

# fuzziness factor
# for hard clustering set to 1
fuzziness = 1

# confidence interval for optimal choice of number of clusters
# alpha% of the SSE values of synthetic datasets clustered for K clusters must be less than the SSE value of the
# actual dataset clustered for K+1 clusters to settle for K clusters
# increasing this value will favour greater number of clusters
# =0.4 for high, 0.1 for low
alpha = 0.05

# csv data path
csv_path = ./loaddata.csv

# comma-seperated customer id(s) of customer data to analyse
customer_ids = 1000, 1001, 1002

# features to consider in the data. Select from [Month, DayOfWeek, Hour, Energy]
feature_names = Hour, Energy

# how many steps should be considered when deciding if it is time to recalculate Kopt. If DBI has been continuously
# decelerating over this number of steps+2, then perform Kopt check
# greater size to track greater time-span
window_size = 2
